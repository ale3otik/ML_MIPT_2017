{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import scipy.stats as sps\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 2, 5, 7, 8, 1, 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188920\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"linear_train.txt\",names=['x','y'])\n",
    "test_data = pd.read_csv(\"linear_test.txt\",names=['x'])\n",
    "test_data = list(test_data['x'])\n",
    "train_xx = list(train_data['x'])\n",
    "train_yy = list(train_data['y'])\n",
    "indices = list(np.arange(len(train_xx)))\n",
    "indices = random.sample(indices,len(indices))\n",
    "train_xx = [train_xx[i] for i in indices]\n",
    "train_yy = [train_yy[i] for i in indices]\n",
    "C = int(len(train_xx) * 0.6)\n",
    "train_x = train_xx[0:C]\n",
    "test_x = train_xx[C:]\n",
    "train_y = train_yy[0:C]\n",
    "test_y = train_yy[C:]\n",
    "# print(train_y)\n",
    "\n",
    "print(len(test_data))\n",
    "# test_data = [test_data[i] for i in np.arange(0,len(test_data),100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7471\n",
      "63514\n"
     ]
    }
   ],
   "source": [
    "print(sum(y == 1 for y in train_y))\n",
    "print(sum(y == 0 for y in train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = [0.0,2.6,3,5,6,0,0,0,0,0,0]\n",
    "pen = [0.0,0.1,0.2,0.5,0.5,0,0,0,0,0]\n",
    "# suf_reward = [1,2]\n",
    "# suf_pen = [0.1,0.2]\n",
    "KK = 6\n",
    "KS = 5\n",
    "def build_tf_idf(X,Y):\n",
    "    succes_qnt = dict()\n",
    "    all_qnt = dict() \n",
    "    suff_succes_qnt = dict()\n",
    "    suff_all_qnt = dict() \n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for k in range(0,KK):\n",
    "            if len(X[i]) > k:\n",
    "                w = X[i][-k-1:]\n",
    "                if w not in all_qnt:\n",
    "                    all_qnt[w] = 0\n",
    "                all_qnt[w] += 1\n",
    "                if Y[i] == 1:\n",
    "                    if w not in succes_qnt:\n",
    "                        succes_qnt[w] = 0\n",
    "                    succes_qnt[w] += 1\n",
    "        for k in range(0,KS):\n",
    "            if len(X[i]) > k+1:\n",
    "                w = X[i][-k-2:-1]\n",
    "                if w not in suff_all_qnt:\n",
    "                    suff_all_qnt[w] = 0\n",
    "                suff_all_qnt[w] += 1\n",
    "                if Y[i] == 1:\n",
    "                    if w not in suff_succes_qnt:\n",
    "                        suff_succes_qnt[w] = 0\n",
    "                    suff_succes_qnt[w] += 1\n",
    "\n",
    "\n",
    "    tf_idf = dict()\n",
    "    tf_idf_suf = dict()\n",
    "    N = np.sum(Y)\n",
    "    for w in succes_qnt:\n",
    "#         tf = succes_qnt[w]/N\n",
    "        tf = abs(succes_qnt[w]/N -  (all_qnt[w] - succes_qnt[w])/(len(Y)))\n",
    "        idf = len(Y)/all_qnt[w]\n",
    "        tf_idf[w] = tf * np.log(idf)\n",
    "    for w in suff_succes_qnt:\n",
    "#         tf = succes_qnt[w]/N\n",
    "        tf = abs(suff_succes_qnt[w]/N -  (suff_all_qnt[w] - suff_succes_qnt[w])/(len(Y)))\n",
    "        idf = len(Y)/suff_all_qnt[w]\n",
    "        tf_idf_suf[w] = tf * np.log(idf)\n",
    "    return [tf_idf, tf_idf_suf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########FEATURES############\n",
    "# KS = 2\n",
    "stat = build_tf_idf(train_x, train_y)\n",
    "tf_idf = stat[0]\n",
    "tf_idf_suff = stat[1]\n",
    "\n",
    "def get_top_from_tfidf(source,length) :\n",
    "    pairs = []\n",
    "    for w in source:\n",
    "        pairs.append((source[w],w))\n",
    "        \n",
    "    pairs = list(reversed(sorted(pairs)))\n",
    "#     for x in pairs[0:20]:\n",
    "#         print(x)\n",
    "    pairs = pairs[:min(len(pairs),length)]\n",
    "    top_ends = set()\n",
    "    for p in pairs:\n",
    "        top_ends.add(p[1])\n",
    "    return top_ends\n",
    "    \n",
    "top_ends = get_top_from_tfidf(tf_idf,800)\n",
    "top_suffs = get_top_from_tfidf(tf_idf_suff,800)\n",
    "# suf_dicts = build_suff(train_x,train_y)\n",
    "\n",
    "##################################################\n",
    "def is_upper_first(w):\n",
    "    return int(w[0].isupper())\n",
    "\n",
    "mean_isupper = np.mean([sum(x.isupper() for x in w) for w in train_x])\n",
    "std_isupper = np.std([sum(x.isupper() for x in w) for w in train_x])\n",
    "mean_trash = np.mean([len(w) - sum(x.isalpha() for x in w) for w in train_x])\n",
    "std_trash = np.std([len(w) - sum(x.isalpha() for x in w) for w in train_x])\n",
    "\n",
    "def number_of_upper(w):\n",
    "    return (sum(x.isupper() for x in w) - mean_isupper)/std_isupper\n",
    "\n",
    "def symbol_statistic(w):\n",
    "    count = dict()\n",
    "    for x in alp:\n",
    "        count[x] = 0\n",
    "    for x in w:\n",
    "        if x in count :\n",
    "            count[x] += 1\n",
    "    return [count[k]/len(w) for k in count]\n",
    "\n",
    "def num_of_trash(w):\n",
    "    return (len(w) - sum(x.isalpha() for x in w) - mean_trash)/std_trash\n",
    "\n",
    "def ending_score_tfidf(w,k):\n",
    "    if len(w) < k:\n",
    "        return tf_idf_mean\n",
    "    x = w[-k-1:]\n",
    "    if x in tf_idf:\n",
    "        return tf_idf[x]\n",
    "    return tf_idf_mean\n",
    "\n",
    "def ending_score_stupid(w,k):\n",
    "    if len(w) < k:\n",
    "        return 0\n",
    "    x = w[-k-1:]\n",
    "    if x in my_tf:\n",
    "        return my_tf[x] / np.sqrt(len(train_x))\n",
    "    return 0\n",
    "\n",
    "def suff_binary(w,x):\n",
    "    if len(w) < len(x) + 1:\n",
    "        return 0\n",
    "    if w[-1*len(x)-1:-1] == x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ending_binary_plus(w,x):\n",
    "    if len(w) < len(x):\n",
    "        return 0\n",
    "    if w[-1*len(x):] == x:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22071\n",
      "20\n",
      "ер\n",
      "ова\n",
      "са\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(len(tf_idf))\n",
    "print(len(top_ends))\n",
    "for x in top_ends:\n",
    "    i+= 1\n",
    "    if i == 4:\n",
    "        break\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_len = np.mean([len(x) for x in train_x])\n",
    "std_len = np.std([len(x) for x in train_x])\n",
    "def get_features(w):\n",
    "    if type(w) != str:\n",
    "        w = w[0]\n",
    "    result = []\n",
    "    result.append(is_upper_first(w))\n",
    "    result.append((len(w) - mean_len)/std_len)\n",
    "    result.append(number_of_upper(w))\n",
    "    result.append(num_of_trash(w))\n",
    "#     for k in range(1,KK):\n",
    "#         result.append(ending_score_tfidf(w,k))\n",
    "#     for k in range(1,KK):\n",
    "#         result.append(ending_score_stupid(w,k))\n",
    "    for x in top_ends:\n",
    "        result.append(ending_binary_plus(w,x))\n",
    "    for x in top_suffs:\n",
    "        result.append(suff_binary(w,x))\n",
    "    return result\n",
    "def get_features_for_data(data):\n",
    "    return [get_features(w) for w in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=300,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.900020417107\n"
     ]
    }
   ],
   "source": [
    "# print(cross_val_score(regressor,features,train_yy,scoring='roc_auc',n_jobs=4))\n",
    "features = get_features_for_data(test_x)\n",
    "print(features[0])\n",
    "regressor.fit(features,test_y)\n",
    "y_check_both = regressor.predict_proba(features)\n",
    "y_check = [y[1] for y in y_check_both]\n",
    "# print(regressor.score(features,train_y))\n",
    "print(roc_auc_score(test_y,y_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = get_features_for_data(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(get_features_for_data(train_x),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912569341828\n"
     ]
    }
   ],
   "source": [
    "y_check_both = regressor.predict_proba(features)\n",
    "y_check = [y[1] for y in y_check_both]\n",
    "print(roc_auc_score(train_y,y_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09169213  0.90830787]\n",
      " [ 0.46182732  0.53817268]\n",
      " [ 0.23060508  0.76939492]\n",
      " [ 0.49901427  0.50098573]\n",
      " [ 0.12117585  0.87882415]\n",
      " [ 0.15142828  0.84857172]\n",
      " [ 0.22485234  0.77514766]\n",
      " [ 0.2946829   0.7053171 ]\n",
      " [ 0.2946829   0.7053171 ]\n",
      " [ 0.17676626  0.82323374]\n",
      " [ 0.17676626  0.82323374]\n",
      " [ 0.28562703  0.71437297]\n",
      " [ 0.42294444  0.57705556]\n",
      " [ 0.22469684  0.77530316]\n",
      " [ 0.45466117  0.54533883]\n",
      " [ 0.2019476   0.7980524 ]\n",
      " [ 0.15137018  0.84862982]\n",
      " [ 0.34267385  0.65732615]\n",
      " [ 0.04120906  0.95879094]\n",
      " [ 0.00708535  0.99291465]]\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# res = regressor.decision_function(features)\n",
    "res = regressor.predict_proba(get_features_for_data(test_data))\n",
    "\n",
    "print(res[0:20])\n",
    "# print(res2[0:20])\n",
    "print(train_y[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.091692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.461827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.230605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.499014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.121176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.151428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.224852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.294683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.294683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.176766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Answer\n",
       "0   0  0.091692\n",
       "1   1  0.461827\n",
       "2   2  0.230605\n",
       "3   3  0.499014\n",
       "4   4  0.121176\n",
       "5   5  0.151428\n",
       "6   6  0.224852\n",
       "7   7  0.294683\n",
       "8   8  0.294683\n",
       "9   9  0.176766"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"linear_ans_example.txt\")\n",
    "submission['Id'] = [i for i in range(len(res))]\n",
    "submission['Answer'] = res\n",
    "submission.to_csv(\"submission_next.txt\", sep=',', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
