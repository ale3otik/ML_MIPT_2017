{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import scipy.stats as sps\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import gmean\n",
    "import scipy.sparse as sprs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 2, 5, 7, 8, 1, 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188920\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"linear_train.txt\",names=['x','y'])\n",
    "test_data = pd.read_csv(\"linear_test.txt\",names=['x'])\n",
    "test_data = list(test_data['x'])\n",
    "train_xx = list(train_data['x'])\n",
    "train_yy = list(train_data['y'])\n",
    "indices = list(np.arange(len(train_xx)))\n",
    "indices = random.sample(indices,len(indices))\n",
    "# train_xx = [train_xx[i] for i in indices]\n",
    "# train_yy = [train_yy[i] for i in indices]\n",
    "# C = int(len(train_xx) * 0.6)\n",
    "train_x = train_xx[0:]\n",
    "# test_x = train_xx[C:]\n",
    "train_y = train_yy[0:]\n",
    "# test_y = train_yy[C:]\n",
    "# print(train_y)\n",
    "\n",
    "print(len(test_data))\n",
    "# test_data = [test_data[i] for i in np.arange(0,len(test_data),100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7471\n",
      "63514\n"
     ]
    }
   ],
   "source": [
    "print(sum(y == 1 for y in train_y))\n",
    "print(sum(y == 0 for y in train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = [0.0,2.6,3,5,6,0,0,0,0,0,0]\n",
    "pen = [0.0,0.1,0.2,0.5,0.5,0,0,0,0,0]\n",
    "# suf_reward = [1,2]\n",
    "# suf_pen = [0.1,0.2]\n",
    "KK = 6\n",
    "KS = 5\n",
    "def build_tf_idf(X,Y):\n",
    "    succes_qnt = dict()\n",
    "    all_qnt = dict() \n",
    "    suff_succes_qnt = dict()\n",
    "    suff_all_qnt = dict() \n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for k in range(0,KK):\n",
    "            if len(X[i]) > k:\n",
    "                w = X[i][-k-1:]\n",
    "                if w not in all_qnt:\n",
    "                    all_qnt[w] = 0\n",
    "                all_qnt[w] += 1\n",
    "                if Y[i] == 1:\n",
    "                    if w not in succes_qnt:\n",
    "                        succes_qnt[w] = 0\n",
    "                    succes_qnt[w] += 1\n",
    "        for k in range(0,KS):\n",
    "            if len(X[i]) > k+1:\n",
    "                w = X[i][-k-2:-1]\n",
    "                if w not in suff_all_qnt:\n",
    "                    suff_all_qnt[w] = 0\n",
    "                suff_all_qnt[w] += 1\n",
    "                if Y[i] == 1:\n",
    "                    if w not in suff_succes_qnt:\n",
    "                        suff_succes_qnt[w] = 0\n",
    "                    suff_succes_qnt[w] += 1\n",
    "\n",
    "\n",
    "    tf_idf = dict()\n",
    "    tf_idf_suf = dict()\n",
    "    N = np.sum(Y)\n",
    "    for w in succes_qnt:\n",
    "#         tf = succes_qnt[w]/N\n",
    "        tf = abs(succes_qnt[w]/N -  (all_qnt[w] - succes_qnt[w])/(len(Y)))\n",
    "        idf = len(Y)/all_qnt[w]\n",
    "        tf_idf[w] = tf * np.log(idf)\n",
    "    for w in suff_succes_qnt:\n",
    "#         tf = succes_qnt[w]/N\n",
    "        tf = abs(suff_succes_qnt[w]/N -  (suff_all_qnt[w] - suff_succes_qnt[w])/(len(Y)))\n",
    "        idf = len(Y)/suff_all_qnt[w]\n",
    "        tf_idf_suf[w] = tf * np.log(idf)\n",
    "    return [tf_idf, tf_idf_suf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########FEATURES############\n",
    "# KS = 2\n",
    "stat = build_tf_idf(train_x, train_y)\n",
    "tf_idf = stat[0]\n",
    "tf_idf_suff = stat[1]\n",
    "\n",
    "def get_top_from_tfidf(source,length) :\n",
    "    pairs = []\n",
    "    for w in source:\n",
    "        pairs.append((source[w],w))\n",
    "        \n",
    "    pairs = list(reversed(sorted(pairs)))\n",
    "#     for x in pairs[0:20]:\n",
    "#         print(x)\n",
    "    pairs = pairs[:min(len(pairs),length)]\n",
    "    top_ends = set()\n",
    "    for p in pairs:\n",
    "        top_ends.add(p[1])\n",
    "    return top_ends\n",
    "    \n",
    "top_ends = get_top_from_tfidf(tf_idf,800)\n",
    "top_suffs = get_top_from_tfidf(tf_idf_suff,800)\n",
    "# suf_dicts = build_suff(train_x,train_y)\n",
    "\n",
    "##################################################\n",
    "def is_upper_first(w):\n",
    "    return int(w[0].isupper())\n",
    "\n",
    "mean_isupper = np.mean([sum(x.isupper() for x in w) for w in train_x])\n",
    "std_isupper = np.std([sum(x.isupper() for x in w) for w in train_x])\n",
    "mean_trash = np.mean([len(w) - sum(x.isalpha() for x in w) for w in train_x])\n",
    "std_trash = np.std([len(w) - sum(x.isalpha() for x in w) for w in train_x])\n",
    "\n",
    "def number_of_upper(w):\n",
    "    return (sum(x.isupper() for x in w) - mean_isupper)/std_isupper\n",
    "\n",
    "def symbol_statistic(w):\n",
    "    count = dict()\n",
    "    for x in alp:\n",
    "        count[x] = 0\n",
    "    for x in w:\n",
    "        if x in count :\n",
    "            count[x] += 1\n",
    "    return [count[k]/len(w) for k in count]\n",
    "\n",
    "def num_of_trash(w):\n",
    "    return (len(w) - sum(x.isalpha() for x in w) - mean_trash)/std_trash\n",
    "\n",
    "def ending_score_tfidf(w,k):\n",
    "    if len(w) < k:\n",
    "        return tf_idf_mean\n",
    "    x = w[-k-1:]\n",
    "    if x in tf_idf:\n",
    "        return tf_idf[x]\n",
    "    return tf_idf_mean\n",
    "\n",
    "def ending_score_stupid(w,k):\n",
    "    if len(w) < k:\n",
    "        return 0\n",
    "    x = w[-k-1:]\n",
    "    if x in my_tf:\n",
    "        return my_tf[x] / np.sqrt(len(train_x))\n",
    "    return 0\n",
    "\n",
    "def suff_binary(w,x):\n",
    "    if len(w) < len(x) + 1:\n",
    "        return 0\n",
    "    if w[-1*len(x)-1:-1] == x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ending_binary_plus(w,x):\n",
    "    if len(w) < len(x):\n",
    "        return 0\n",
    "    if w[-1*len(x):] == x:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22071\n",
      "20\n",
      "ер\n",
      "ова\n",
      "са\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(len(tf_idf))\n",
    "print(len(top_ends))\n",
    "for x in top_ends:\n",
    "    i+= 1\n",
    "    if i == 4:\n",
    "        break\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_len = np.mean([len(x) for x in train_x])\n",
    "std_len = np.std([len(x) for x in train_x])\n",
    "def get_features(w):\n",
    "    if type(w) != str:\n",
    "        w = w[0]\n",
    "    result = []\n",
    "    result.append(is_upper_first(w))\n",
    "    result.append((len(w) - mean_len)/std_len)\n",
    "    result.append(number_of_upper(w))\n",
    "    result.append(num_of_trash(w))\n",
    "#     for k in range(1,KK):\n",
    "#         result.append(ending_score_tfidf(w,k))\n",
    "#     for k in range(1,KK):\n",
    "#         result.append(ending_score_stupid(w,k))\n",
    "#     for x in top_ends:\n",
    "#         result.append(ending_binary_plus(w,x))\n",
    "#     for x in top_suffs:\n",
    "#         result.append(suff_binary(w,x))\n",
    "    return result\n",
    "def get_features_for_data(data):\n",
    "    return [get_features(w) for w in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=800,n_jobs=4,C=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-51113f72aa48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(cross_val_score(regressor,features,train_yy,scoring='roc_auc',n_jobs=4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_for_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_check_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "# print(cross_val_score(regressor,features,train_yy,scoring='roc_auc',n_jobs=4))\n",
    "features = get_features_for_data(test_x)\n",
    "print(features[0])\n",
    "regressor.fit(features,test_y)\n",
    "y_check_both = regressor.predict_proba(features)\n",
    "y_check = [y[1] for y in y_check_both]\n",
    "# print(regressor.score(features,train_y))\n",
    "print(roc_auc_score(test_y,y_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = get_features_for_data(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(get_features_for_data(train_x),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912569341828\n"
     ]
    }
   ],
   "source": [
    "y_check_both = regressor.predict_proba(features)\n",
    "y_check = [y[1] for y in y_check_both]\n",
    "print(roc_auc_score(train_y,y_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(2, 6), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=2, max_df=.8,\n",
    "                             max_features=None,\n",
    "                             ngram_range=(2, 6),\n",
    "                             lowercase=False,\n",
    "                             analyzer='char_wb',\n",
    "                             binary=False)\n",
    "vectorizer.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.15665406 -0.03655884 ...,  0.          0.          0.        ]\n",
      " [ 1.         -1.89666747 -0.03655884 ...,  0.          0.          0.        ]\n",
      " [ 1.         -1.2006621  -0.03655884 ...,  0.          0.          0.        ]\n",
      " [ 1.         -1.2006621   1.64383038 ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "features1 = get_features_for_data(train_x)\n",
    "features2 = vectorizer.transform(train_x)\n",
    "features = sprs.hstack([features1, sprs.coo_matrix(features2)])\n",
    "print(features.toarray()[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72801231  0.82755968  0.90249098]\n"
     ]
    }
   ],
   "source": [
    "regressor = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=800,n_jobs=4,C=4)\n",
    "print(cross_val_score(regressor,features,train_y,n_jobs=4))\n",
    "# regressor.fit(features,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor.fit(features,train_y)\n",
    "features1 = get_features_for_data(test_data)\n",
    "features2 = vectorizer.transform(test_data)\n",
    "features = sprs.hstack([features1, sprs.coo_matrix(features2)])\n",
    "res = regressor.predict_proba(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97234282821\n"
     ]
    }
   ],
   "source": [
    "features1 = get_features_for_data(train_x)\n",
    "features2 = vectorizer.transform(train_x)\n",
    "features = sprs.hstack([features1, sprs.coo_matrix(features2)])\n",
    "y_check_both = regressor.predict_proba(features)\n",
    "y_check = [y[1] for y in y_check_both]\n",
    "# print(regressor.score(features,train_y))\n",
    "print(roc_auc_score(train_y,y_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.39338323e-01   8.60661677e-01]\n",
      " [  2.12199563e-01   7.87800437e-01]\n",
      " [  4.97338897e-01   5.02661103e-01]\n",
      " [  8.34889923e-01   1.65110077e-01]\n",
      " [  4.70740060e-01   5.29259940e-01]\n",
      " [  4.55233748e-01   5.44766252e-01]\n",
      " [  3.67900777e-01   6.32099223e-01]\n",
      " [  5.17674022e-01   4.82325978e-01]\n",
      " [  5.17674022e-01   4.82325978e-01]\n",
      " [  6.16992052e-01   3.83007948e-01]\n",
      " [  6.16992052e-01   3.83007948e-01]\n",
      " [  7.29135119e-01   2.70864881e-01]\n",
      " [  8.65525150e-01   1.34474850e-01]\n",
      " [  8.60155048e-01   1.39844952e-01]\n",
      " [  7.14109637e-01   2.85890363e-01]\n",
      " [  7.88934280e-01   2.11065720e-01]\n",
      " [  4.65396685e-01   5.34603315e-01]\n",
      " [  6.58476166e-01   3.41523834e-01]\n",
      " [  3.56841506e-03   9.96431585e-01]\n",
      " [  2.78160045e-04   9.99721840e-01]]\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# res = regressor.decision_function(features)\n",
    "# res = regressor.predict_proba(get_features_for_data(test_data))\n",
    "\n",
    "print(res[0:20])\n",
    "# print(res2[0:20])\n",
    "print(train_y[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.281771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.406573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.791670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.957159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.858107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.759695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.901385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.893743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.893743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.931495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Answer\n",
       "0   0  0.281771\n",
       "1   1  0.406573\n",
       "2   2  0.791670\n",
       "3   3  0.957159\n",
       "4   4  0.858107\n",
       "5   5  0.759695\n",
       "6   6  0.901385\n",
       "7   7  0.893743\n",
       "8   8  0.893743\n",
       "9   9  0.931495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"linear_ans_example.txt\")\n",
    "submission['Id'] = [i for i in range(len(res))]\n",
    "submission['Answer'] = res\n",
    "submission.to_csv(\"submission_next.txt\", sep=',', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"submission_merge_1.txt\")\n",
    "d2 = pd.read_csv(\"submission_merge_2.txt\")\n",
    "v1 = np.array(list(d1['Answer']))\n",
    "v2 = np.array(list(d2['Answer']))\n",
    "v3 = gmean([v1,v2])\n",
    "d1['Id'] = [i for i in range(len(v1))]\n",
    "d1['Answer'] = v3\n",
    "d1.to_csv(\"submission_merged_super.txt\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.657842846620866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(1e30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
